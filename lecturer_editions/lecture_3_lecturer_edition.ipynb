{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><ul class=\"toc-item\"><li><span><a href=\"#Steps:\" data-toc-modified-id=\"Steps:-0.1\"><span class=\"toc-item-num\">0.1&nbsp;&nbsp;</span>Steps:</a></span></li><li><span><a href=\"#General\" data-toc-modified-id=\"General-0.2\"><span class=\"toc-item-num\">0.2&nbsp;&nbsp;</span>General</a></span></li></ul></li><li><span><a href=\"#DATA\" data-toc-modified-id=\"DATA-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>DATA</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-directories\" data-toc-modified-id=\"Data-directories-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Data directories</a></span></li></ul></li><li><span><a href=\"#Model\" data-toc-modified-id=\"Model-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Define-the-model-layers\" data-toc-modified-id=\"Define-the-model-layers-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Define the model layers</a></span></li><li><span><a href=\"#Compile-the-model\" data-toc-modified-id=\"Compile-the-model-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Compile the model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Model-summary\" data-toc-modified-id=\"Model-summary-2.2.1\"><span class=\"toc-item-num\">2.2.1&nbsp;&nbsp;</span>Model summary</a></span></li><li><span><a href=\"#Plot-a-graph-of-the-model-architecture\" data-toc-modified-id=\"Plot-a-graph-of-the-model-architecture-2.2.2\"><span class=\"toc-item-num\">2.2.2&nbsp;&nbsp;</span>Plot a graph of the model architecture</a></span></li></ul></li><li><span><a href=\"#Train-the-model\" data-toc-modified-id=\"Train-the-model-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Train the model</a></span></li><li><span><a href=\"#Plot--the-learning-curves\" data-toc-modified-id=\"Plot--the-learning-curves-2.4\"><span class=\"toc-item-num\">2.4&nbsp;&nbsp;</span>Plot  the learning curves</a></span></li><li><span><a href=\"#Test-model-on-'test'-dataset\" data-toc-modified-id=\"Test-model-on-'test'-dataset-2.5\"><span class=\"toc-item-num\">2.5&nbsp;&nbsp;</span>Test model on <em>'test'</em> dataset</a></span></li></ul></li><li><span><a href=\"#Dropout\" data-toc-modified-id=\"Dropout-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Dropout</a></span></li><li><span><a href=\"#Augmentation\" data-toc-modified-id=\"Augmentation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Augmentation</a></span></li><li><span><a href=\"#Transfer-learning\" data-toc-modified-id=\"Transfer-learning-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Transfer learning</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification with Convolutional Neural Networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of this notebook is to showcase in practice - i.e. in code - how to build a simple CNN for the purpose of classifying image data.\n",
    "\n",
    "The dataset used is intentionally a relatively small dataset, for the sake of time economy, but also in order to reduce the computational resources required.\n",
    "\n",
    "\n",
    "Remember: https://keras.io is a useful source of information regarding Keras and Tensorflow.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Steps:\n",
    "\n",
    "1) DATA. As a first step we will load the original data and divide the available images into three datasets (training, validation, test). \n",
    "\n",
    "2) MODEL. Build the network architecture: this is the part where we put together the code which: describes the neural network, processes the images, and feeds the images into the network for training.\n",
    "\n",
    "3) LEARNING CURVES. Once the training is finished, plot the performance of the trained model \n",
    "\n",
    "4) DROPOUT. A first effort to improve the performance of the model (if we observed overfitting earlier).\n",
    "\n",
    "5) AUGMENTATION. Another way to improve model accuracy or avoid overfitting\n",
    "\n",
    "6) TRANSFER LEARNING. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General\n",
    "\n",
    "Let's start by importing **various useful** libraries in one go. \n",
    "We also check the versions of keras and tensorflow he have in our disposal (because we can).\n",
    "If more libraries become needed later on, come back to the cell below and add them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import optimizers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "import os, shutil\n",
    "from shutil import copyfile\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "print(keras.__version__)\n",
    "print(tensorflow.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA\n",
    "\n",
    "\n",
    "We will use an existing dataset, dowloaded from kaggle (https://www.kaggle.com/alxmamaev/flowers-recognition)\n",
    "\n",
    "This is a set of images of 5 different types of flowers. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data directories\n",
    "\n",
    "**Create a hierarchy of directories**, with seperate directories for *training*,  *validation*, and *test* datasets. Each of these will contain a subdirectory for each *class*.\n",
    "\n",
    "_Important_: __obviously, building the datasets only needs to be done once.__ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the line below define a 'base' name of an existing directory where you want to store \n",
    "# the original folder with the images and the datasets you are about to create.\n",
    "# Something like:  base = '/mnt/ceph/home/r1111683/data'\n",
    "\n",
    "base='/mnt/ceph/home/r1111683/data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# define the directory to store the datasets\n",
    "classification_data_path=os.path.join(base + '/flower_classification_data') \n",
    "\n",
    "# create that directory\n",
    "if not os.path.exists(classification_data_path):\n",
    "  os.mkdir(classification_data_path)\n",
    "\n",
    "# define datasets (i.e. subdirs within the 'base' dir) and define classes (i.e. sub-subdirs for each of the dataset directories)\n",
    "datasets=['train','validation','test']\n",
    "classes=['daisy','dandelion','rose','sunflower','tulip']\n",
    "\n",
    "# create that hierarchy of dirs and subdirs\n",
    "for dtype in datasets:\n",
    "  path_set=os.path.join(classification_data_path,dtype)\n",
    "  if not os.path.exists(path_set):\n",
    "    os.mkdir(path_set)\n",
    "  for c in classes:\n",
    "    path_class=os.path.join(path_set,c)\n",
    "    if not os.path.exists(path_class):\n",
    "      os.mkdir(path_class)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function  - named 'pop_dirs' - for splitting the data into train, validation, and test data (after shuffling them) \n",
    "# and populating the directory tree created above.\n",
    "\n",
    "def pop_dirs(SOURCE, TRAINING, VALIDATION, TEST, SPLIT_SIZE):\n",
    "    files = []\n",
    "    for filename in os.listdir(SOURCE):\n",
    "        file = SOURCE + filename\n",
    "        if os.path.getsize(file) > 0:\n",
    "            files.append(filename)\n",
    "        else:\n",
    "            print(filename + \" is zero length, so ignoring.\")\n",
    "\n",
    "    training_length = int(len(files) * SPLIT_SIZE)\n",
    "    validation_length = int((len(files) - training_length)/2.0)\n",
    "    test_length = validation_length\n",
    "    shuffled_set = random.sample(files, len(files))\n",
    "    training_set = shuffled_set[0:training_length]\n",
    "    validation_set = shuffled_set[training_length:training_length+validation_length]\n",
    "    test_set = shuffled_set[training_length+validation_length:training_length+validation_length+test_length]\n",
    "\n",
    "    for filename in training_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TRAINING + filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "    for filename in validation_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = VALIDATION + filename\n",
    "        copyfile(this_file, destination)\n",
    "\n",
    "    for filename in test_set:\n",
    "        this_file = SOURCE + filename\n",
    "        destination = TEST + filename\n",
    "        copyfile(this_file, destination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The actual copying of files from the 'data' folder into the folder hierarchy created earlier. \n",
    "\n",
    "j=0\n",
    "# fraction of data (from 0.0 to 1.0) to be used as training data. The rest will be split equally a\n",
    "split_size = .7   \n",
    "\n",
    "#classes=['daisy','dandelion','rose','sunflower','tulip']   \n",
    "\n",
    "for c in classes:\n",
    "\n",
    "  src_path=os.path.join(base,'flowers',c)+'/'\n",
    "\n",
    "  train_path=os.path.join(base,'flower_classification_data/train',c)+'/' \n",
    "  validation_path=os.path.join(base,'flower_classification_data/validation',c)+'/'\n",
    "  test_path=os.path.join(base,'flower_classification_data/test',c)+'/'\n",
    "\n",
    "  print('Copyting data FROM:')\n",
    "  print(src_path)\n",
    "  print('TO:')\n",
    "  print(train_path)\n",
    "  print(validation_path)\n",
    "  print(test_path)\n",
    "  print('\\n')  \n",
    "    \n",
    "  pop_dirs(src_path, train_path, validation_path, test_path, split_size)\n",
    "  j+=1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the number of images for each dataset and each class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets=['train','validation','test']\n",
    "classes=['daisy','dandelion','rose','sunflower','tulip']\n",
    "\n",
    "for dset in datasets:\n",
    "  for c in classes:\n",
    "    path=os.path.join(base,'flower_classification_data',dset,c)\n",
    "    print('number of',  dset,  'images in', c,':', len(os.listdir(path)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "This section containes the code for the CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run ONLY when clearing of the session is needed\n",
    "\n",
    "tensorflow.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Place needed and updatable parameters in a dictionary for easy access and change\n",
    "PARAMS = {'lr': 5e-5, # Learning Rate\n",
    "          'dropout': 0.6,\n",
    "          'batch_size': 32,\n",
    "          'n_epochs': 50,\n",
    "          'loss': 'categorical_crossentropy',\n",
    "          'metrics': 'acc', # accuracy\n",
    "          'image_input_shape' : (100,100,3),\n",
    "          'save_model' : 'flower_classification_1.h5'\n",
    "          }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_datagen = ImageDataGenerator(samplewise_center=True,samplewise_std_normalization=True)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1.0/255.,horizontal_flip=True,vertical_flip=True)\n",
    "validation_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "test_datagen = ImageDataGenerator(rescale = 1.0/255.)\n",
    "\n",
    "train = train_datagen.flow_from_directory(\n",
    "        classification_data_path+'/train',\n",
    "        target_size=(100, 100),\n",
    "        batch_size=PARAMS['batch_size'],\n",
    "        class_mode='categorical') \n",
    "\n",
    "validation = validation_datagen.flow_from_directory(\n",
    "        classification_data_path+'/validation',\n",
    "        target_size=(100, 100),\n",
    "        batch_size=PARAMS['batch_size'],\n",
    "        class_mode='categorical')\n",
    "\n",
    "\n",
    "test = test_datagen.flow_from_directory(\n",
    "        classification_data_path+'/test',\n",
    "        target_size=(100, 100),\n",
    "        batch_size=PARAMS['batch_size'],\n",
    "        class_mode='categorical')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the sizes of the image and label batches (useful for debugging size errors)\n",
    "for images_batch, labels_batch in train:\n",
    "    print('Image batches have shape:', images_batch.shape)\n",
    "    print('Label batches have shape:', labels_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the model layers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Conv2D layers, each of wich will be followed by MaxPooling2D layer. \n",
    "\n",
    "- How many Conv2D layers to use? (in this case 3-5 is a good guess)\n",
    "- Number of filters for each? (powers of two typically used, with number of filters typically increassing in deeper layers, i.e. 32,64,128)\n",
    "- Size of these filters? 3x3, or 5x5, or 7x7 are typical values\n",
    "- A Flatten layer should be added after the last Conv2D layer\n",
    "- Last layer should be a Dense layer with a 'softmax' activation, as we are building a 'classification' model\n",
    "- It is likely that mode Dense layers can be added between the Flatten and the last Dense layer (the output layer).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> **Task 1:**\n",
    "+ Build the CNN, by adding the necessary sequence of layers: use what was discussed in the lecture and in the text just above as quide\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu',\n",
    "                        input_shape=PARAMS['image_input_shape']))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(512,activation='relu'))\n",
    "model.add(layers.Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=PARAMS['loss'],\n",
    "              optimizer=optimizers.RMSprop(lr=PARAMS['lr']),\n",
    "              metrics=[PARAMS['metrics']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model summary\n",
    "\n",
    "Draw a summary of each layer of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot a graph of the model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a graph of the model layers\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model.png',show_shapes=True,rankdir='TB',show_layer_names=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model \n",
    "spe=len(train)   # Steps Per Epoch: train_size/batch_size\n",
    "epoch_num=PARAMS['n_epochs']\n",
    "val_steps=len(validation)  # validation_size/batch_size\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "            train,\n",
    "            steps_per_epoch=spe,  \n",
    "            epochs=epoch_num,\n",
    "            validation_data=validation,\n",
    "            validation_steps=val_steps) \n",
    "\n",
    "\n",
    "# To save the output of the model, uncomment the line below\n",
    "#model.save(PARAMS['save_model'])\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot  the learning curves "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the progress of the training, by plotting the Learning Curves:\n",
    "# a) Accuracy of the model on the train and validation datasets as a function of epochs (time)\n",
    "# b) Value of loss function on train and validation datasets as a function of epochs\n",
    "\n",
    "# if the model was saved from an earlier run, uncomment the line below to load it\n",
    "#model = load_model('name_of_model_to_load.h5')\n",
    "\n",
    "epoch_num=PARAMS['n_epochs']\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "plt.plot(range(epoch_num), acc, 'b', label='Training accuracy')\n",
    "plt.plot(range(epoch_num), val_acc, 'g', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(epoch_num), loss, 'b', label='Training loss')\n",
    "plt.plot(range(epoch_num), val_loss, 'g', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model on *'test'* dataset\n",
    "\n",
    "As a final step on checking the performance of the model, we run the trained model on the third dataset, the 'test' dataset. (These are data that our model has not seen yet).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_score = model.evaluate(test)\n",
    "print(model.metrics_names)\n",
    "print(test_score)\n",
    "print()\n",
    "print(\"Accuracy = \",test_score[1]*100,'%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dropout\n",
    "\n",
    "\n",
    "One way to overcome overfitting of the model is to add one or more Dropout layers in the model.\n",
    "\n",
    "A 'Dropout' layer will randomly drop-out (i.e. remove) a user-defined number of nodes (i.e. connections) between two layers.\n",
    "\n",
    "Adding a dropout layer looks like this:\n",
    "    *model.add(layers.Dropout(0.5))*\n",
    "The argument of Dropout is a number from 0.0 to 1.0 which corresponds to the fraction of nodes to **remove** . \n",
    "\n",
    "A typical value  is around 0.5-0.6 (i.e. 50-60% or the nodes removed).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Task 2**\n",
    "Add a Dropout Layer (or try adding more that one) in the model you created earlier and train the model again.\n",
    "    \n",
    "**NOTE:** \n",
    " + remember to clear the session with the command available at the beginning of Section 2\n",
    " + must run again the cell with the model architecture, and compile the model again before fitting the new architecture.   \n",
    "</font>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One possible remedy for overfitting, when it is caused by lack of enough data, is to use data augmentation.\n",
    "In data augmentation, already existing data - images in our case - are 'tranformed' into new data through some basic transformations like mirroring or flipping, rotation, zoom, rescaling, etc.  of the image.\n",
    "\n",
    "\n",
    "In Keras, the ImageDataGenerator class, offers an easy way to include these augm,entation techniques.\n",
    "Check the ImageDataGenerator entry here:https://keras.io/api/preprocessing/image/  to see to it is done."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Task 3**\n",
    "-Based on the Keras link above, choose the augmentation transformation which make sense for the dataset you are using, and implement these transformations within the ImageDataGenerator. You can just edit and run the code we used earlier (3d cell in Section 2) or re-write (copy) that cell here and add the relevant arguments for the image augmentation (transformation).   \n",
    "    \n",
    "**NOTE**: augmentation is applied only on the training dataset\n",
    "- Train again the model and plot its performance on the new, augmented dataset.\n",
    "- Do not forget to also test the trained model on the 'test' dataset\n",
    "</font>\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the VGG16 network (https://arxiv.org/abs/1409.1556) trained on the ImageNet dataset (http://image-net.org/about-overview).\n",
    "As it is already part of the Keras library, it is easy to load.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear the prevoius session if needed\n",
    "tensorflow.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import VGG16\n",
    "from tensorflow.keras.applications import VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of the VGG16 network, with input_size to match our dataset, and without including the last output layer(s)\n",
    "pretrained_net = VGG16(input_shape=(100,100,3),include_top=False,weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pretrained_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'Freeze' (i.e. make them untrainable) all layers in thre pretrained network\n",
    "for layer in pretrained_net.layers:\n",
    "    layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a couple of layers at the end of the pretrained network: we need to add our own output layer, \n",
    "# which will classify our data according to the number of classes we have.\n",
    "\n",
    "model2 = models.Sequential()\n",
    "model2.add(pretrained_net)\n",
    "model2.add(layers.Flatten())\n",
    "model2.add(layers.Dense(5, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'> **Task 4:**\n",
    "   \n",
    "- Train the pretrained network (in reallity only the layers we added will be trained, we 'froze' all the layers previous to those) with the same data as before and compaire its performance to that of the previous model.\n",
    "* Add code for plotting the learning curves for this model (you can also choose to overplot the learning curves of the previous model for direct comparison)\n",
    "- Test the accuracty of the model on the 'test' dataset. </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model \n",
    "model2.compile(loss=PARAMS['loss'],\n",
    "              optimizer=optimizers.RMSprop(PARAMS['lr']),\n",
    "              metrics=[PARAMS['metrics']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model \n",
    "spe=len(train)   # train_size/batch_size\n",
    "epoch_num=PARAMS['n_epochs']\n",
    "val_steps=len(validation)  # validation_size/batch_size\n",
    "\n",
    "\n",
    "history = model2.fit(\n",
    "            train,\n",
    "            steps_per_epoch=spe,  \n",
    "            epochs=epoch_num,\n",
    "            validation_data=validation,\n",
    "            validation_steps=val_steps) \n",
    "#model.save(PARAMS['save_model'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# plot learning curves\n",
    "#model = load_model('name_of_model_to_load.h5')\n",
    "epoch_num=PARAMS['n_epochs']\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "\n",
    "plt.plot(range(epoch_num), acc, 'b', label='Training accuracy')\n",
    "plt.plot(range(epoch_num), val_acc, 'g', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(range(epoch_num), loss, 'b', label='Training loss')\n",
    "plt.plot(range(epoch_num), val_loss, 'g', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.legend()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test trained model on 'test' dataset\n",
    "test_score = model2.evaluate(test)\n",
    "print(model2.metrics_names)\n",
    "print(test_score)\n",
    "print()\n",
    "print(\"Accuracy = \",test_score[1]*100,'%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
